# Opus x Bella — Live Demo Cheat Sheet
## Session 7: Doing Research with Generative AI | Feb 26, 2026

---

## ACT 1: "The Receipts" (~1.5 min)
> Screen-share pre-prepared artifacts. Narrate, don't read.

**Show 1 → Theme Map (.jsx artifact)**
- "I gave Claude 6 Harvard writing guides. It extracted 5 cross-disciplinary patterns I now use as my reading framework."

**Show 2 → Reading Guide (HTML)**
- "Used those frameworks to critically analyze today's paper through 5 lenses. Claude found the steel-man objection: if GPT-4 was trained on Friendsgiving content, Study 1 might be measuring retrieval, not generation."

**Show 3 → These Slides (.pptx)**
- "These slides were built programmatically from the paper analysis. The pipeline IS the hybrid method."

**DELIVER:** "I didn't ask Claude to do my work. I directed it — chose the frameworks, the critical questions, the research angle. Claude executed at speed. That's the hybrid."

---

## ACT 2: "The Live Prompt" (~1.5 min)
> Type this prompt live in Cowork (or Claude chat):

```
I'm developing a research idea at the intersection of AI in education,
persuasion theory, and wise interventions. Using the Arora et al. (2025)
hybrid framework (Table 1), map out which stages of my research process
an LLM could assist with — and which stages require human-only judgment.
Be specific to my domain.
```

> Let Claude respond. Point out the table it generates.
> Highlight: "See how it maps the qualitative-to-quantitative pipeline onto MY domain? That's the Table 1 framework applied live."

---

## ACT 3: "The Takeaway" (~30 sec)

**DELIVER:** "Arora et al. found that unique insights emerge from the hybrid that neither produces alone. I can confirm — the critical evaluation, the counterarguments, the cross-disciplinary connections — those came from the collaboration, not from me or Claude in isolation."

**OPTIONAL CLOSER:** "One thing the paper doesn't address: what happens when the human collaborator is trained in persuasion theory? The hybrid gets better when the human brings stronger domain priors."

---

## IF DR. DU ASKS FOLLOW-UP QUESTIONS:

**"What model did you use?"**
→ Claude Opus 4.6 via Cowork (Anthropic's desktop agent). The paper uses GPT-4; I wanted to test cross-model generalizability — exactly the limitation we identified.

**"How much did you do vs. Claude?"**
→ I set the research direction, chose which frameworks to apply, identified which critical questions to pursue, and made every editorial judgment. Claude did the processing: extracting text from PDFs, cross-referencing patterns, generating structured outputs, and building the slides programmatically.

**"Is this really replicating the paper's method?"**
→ Yes — but with a twist. Arora et al. use LLMs for data generation and analysis. I'm using an LLM for the meta-research process itself — reading, analyzing, and preparing to discuss the research. It's the hybrid method applied one level up.

**"What are the limitations of your approach?"**
→ Same as the paper's: I can't verify everything Claude generates without going back to primary sources. And there's a risk of over-reliance — if Claude's reading of the paper has a blind spot, I inherit it unless I independently verify. That's why the human-in-the-loop is non-negotiable.
